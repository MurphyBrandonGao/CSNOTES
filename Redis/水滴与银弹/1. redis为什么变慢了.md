# redis 为什么变慢了

### 1、使用复杂度高的命令

Redis 提供了慢日志（slow log）命令的统计功能，它记录了有哪些命令在执行时耗时比较久。

如果你的应用程序执行的 Redis 命令有以下特点，那么有可能会导致操作延迟变大：

1. 经常使用 O(N) 以上复杂度的命令，例如 SORT、SUNION、ZUNIONSTORE 聚合类命令
2. 使用 O(N) 复杂度的命令，但 N 的值非常大

针对这种情况如何解决呢？

1. 尽量不使用 O(N) 以上复杂度过高的命令，对于数据的聚合操作，放在客户端做
2. 执行 O(N) 命令，保证 N 尽量的小（推荐 N <= 300），每次获取尽量少的数据，让 Redis 可以及时处理返回

### 2、操作bigkey

如果一个 key 写入的 value 非常大，那么 Redis 在**分配内存时就会比较耗时**。同样的，当删除这个 key 时，**释放内存也会比较耗时**，这种类型的 key 我们一般称之为 bigkey。

那针对 bigkey 导致延迟的问题，有什么好的解决方案呢？

这里有两点可以优化：

1. 业务应用尽量避免写入 bigkey
2. 如果你使用的 Redis 是 4.0 以上版本，可以开启 lazy-free 机制（lazyfree-lazy-user-del = yes），在执行 DEL 命令时，释放内存也会放到后台线程中执行
3. 4.0以上版本使用 UNLINK 命令替代 DEL，此命令可以把释放 key 内存的操作放到后台线程去执行，从而降低对 redis 的影响。

一般有两种方案来规避这个问题：

1. 集中过期 key 增加一个随机过期时间，把集中过期的时间打散，降低 Redis 清理过期 key 的压力
2. 如果你使用的 Redis 是 4.0 以上版本，可以开启 lazy-free 机制，当删除过期 key 时，把释放内存的操作放到后台线程中执行，避免阻塞主线程

### 3、实例内存达到上限

当 Redis 内存达到 maxmemory 后，每次写入新的数据之前，**Redis 必须先从实例中踢出一部分数据，让整个实例的内存维持在 maxmemory 之下**，然后才能把新数据写进来。

我给你 4 个方面的优化建议：

1. 避免存储 bigkey，降低释放内存的耗时
2. **淘汰策略改为随机淘汰，随机淘汰比 LRU 要快很多（视业务情况调整）**
3. 拆分实例，把淘汰 key 的压力分摊到多个实例上
4. 如果使用的是 Redis 4.0 以上版本，开启 layz-free 机制，把淘汰 key 释放内存的操作放到后台线程中执行（配置 lazyfree-lazy-eviction = yes）

### 4、fork耗时严重

当 Redis 开启了后台 RDB 和 AOF rewrite 后，在执行时，它们都需要主进程创建出一个子进程进行数据的持久化。主进程创建子进程，会调用操作系统提供的 fork 函数。而 fork 在执行过程中，**主进程需要拷贝自己的内存页表给子进程**，如果这个实例很大，那么这个拷贝的过程也会比较耗时。而且这个 fork 过程会消耗大量的 CPU 资源，在完成 fork 之前，整个 Redis 实例会被阻塞住，无法处理任何客户端请求。

要想避免这种情况，你可以采取以下方案进行优化：

1. 控制 Redis 实例的内存：尽量在 10G 以下，执行 fork 的耗时与实例大小有关，实例越大，耗时越久
2. 合理配置数据持久化策略：在 slave 节点执行 RDB 备份，推荐在低峰期执行，而对于丢失数据不敏感的业务（例如把 Redis 当做纯缓存使用），可以关闭 AOF 和 AOF rewrite
3. Redis 实例不要部署在虚拟机上：fork 的耗时也与系统也有关，虚拟机比物理机耗时更久
4. 降低主从库全量同步的概率：适当调大 repl-backlog-size 参数，避免主从全量同步

### 5、内存碎片整理

如果 mem_fragmentation_ratio > 1.5，说明内存碎片率已经超过了 50%，这时我们就需要采取一些措施来降低内存碎片了。**但是，开启内存碎片整理，它也有可能会导致 Redis 性能下降。**

原因在于，Redis 的碎片整理工作也是在**主线程**中执行的，当其进行碎片整理时，必然会消耗 CPU 资源，产生更多的耗时，从而影响到客户端的请求。
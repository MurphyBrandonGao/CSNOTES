# 第1章 初始kafka

## 1.1 发布与订阅消息系统

数据（消息）的发送者不会直接把消息发送给接收者，这是发布与订阅系统的一个特点。发布者以某种方式对消息进行分类，接收者（订阅者）订阅它们，以便接收特定类型的消息。发布与订阅系统一般会有一个 broker ，也就是发布消息的中心点。

## 1.2 kafka登场

它一般被称为“分布式提交日志”或者“分布式流平台”。文件系统或数据库提交日志用来提供所有事务的持久记录，通过重放这些日志可以重建系统的状态。同样地， Kafka 的数据是按照一定顺序持久化保存的，可以按需读取。此外， kafka 的数据分布在整个系统里，具备数据故障保护和性能伸缩能力。

### 1.2.1 消息和批次

Kafka 的数据单元被称为消息。可以把消息看成是数据库里的一个“数据行”或一条“记录”。消息由字节数组组成，所以对于 Kafka 来说消息里的数据没有特别的格式或含义。消息可以有一个可选的元数据也就是键。**键也是一个字节数组**，与消息一样，对于 Kafka 来说也没有特殊的含义。当消息以一种可控的方式写入不同的分区时，会用到键。比如为键生成一个一致性散列值，然后使用散列值对主题分区数进行取模，为消息选取分区。这样可以保证**具有相同键的消息总是被写到相同的分区上**。

为了提高效率，消息被分批次写入 Kafka。批次就是一组消息，这些消息属于同一个主题和分区。如果每个消息都单独穿行于网络，会导致大量的网络开销，**把消息分成批次传输可以减少网络开销**。不过，这要在时间延迟和吞吐量之间作出权衡：批次越大，单位时间内处理的消息就越多，单个消息的传输时间就越长。批次数据会被压缩，这样可以提升数据的传输和存储能力，但要做更多的计算处理。

### 1.2.2 模式

对于 kafka 来说，消息不过是晦涩难懂的字节数组，所以有人建议用一些额外的结构来定义消息内容，让它们更易于理解。根据应用程序的需求， 消息模式（schema）有许多可用的选项。像 JSON 和 XML 这些简单的系统，不仅易用，而且可读性好。不过，它们缺乏强类型处理能力。Kafka 的许多开发者喜欢使用Apache Avro。Avro 提供了一种紧凑的序列化格式，模式和消息体是分开的，当模式发生变化时，不需要重新生成代码。它还支持强类型和模式进化，其版本既向前兼容， 也向后兼容。

### 1.2.3 主题和分区

Kafka 的消息通过主题进行分类。主题就好比数据库的表，或者文件系统里的文件夹。主题可以被分为若干个分区，**一个分区就是一个提交日志**。消息以追加的方式写入分区，然后以先入先出的顺序读取。要注意，**由于一个主题一般包含几个分区，因此无法在整个主题范围内保证消息的顺序，但可以保证消息在单个分区内的顺序**。下图所示的主题有4个分区，消息被追加写入每个分区的尾部。kafka 通过分区来实现数据冗余和伸缩性。**分区可以分布在不同的服务器上**，也就是说， **一个主题可以横跨多个服务器**，以此来提供比单个服务器更强大的性能。

![image-20211212154252152](https://typora-gao-pic.oss-cn-beijing.aliyuncs.com/image-20211212154252152.png)

### 1.2.4 生产者和消费者

生产者创建消息。**一个消息会被发布到一个特定的主题上**。生产者在默认情况下把消息均衡地分布到主题的所有分区上，而并不关心特定消息会被写到哪个分区。不过，在某些情况下，生产者会把消息直接写到指定的分区。这通常是通过消息键和分区器来实现的，分区器为键生成一个散列值，并将其映射到指定的分区上。这样可以保证包含同一个键的消息会被写到同一个分区上。生产者也可以使用自定义的分区器，根据不同的业务规则将消息映射到分区。

消费者读取消息。消费者订阅一个或多个主题，并按照消息生成的顺序读取它们。消费者通过检查消息的偏移量来区分已经读取过的消息。偏移量是另一种元数据，它是一个不断递增的整数值，在创建消息时， Kafka 会把它添加到消息里。在给定的分区里，每个消息的偏移量都是唯一的。**消费者把每个分区最后读取的消息偏移量保存在 Zookeeper或者 Kafka 上，如果消费者关闭或重启，它的读取状态不会丢失**。

消费者是消费者群组的一部分，也就是说，**会有一个或多个消费者共同读取一个主题**。群组保证每个分区只能被一个消费者使用 。下图所示的群组中，有3个消费者同时读取1个主题。其中的两个消费者各自读取一个分区，另外2个消费者读取其他两个分区。**消费者与分区之间的映射通常被称为消费者对分区的所有权关系**。通过这种方式，消费者可以消费包含大量消息的主题。而且如果一个消费者失效，群组里的其他消费者可以接管失效消费者的工作。

![image-20211212160604076](https://typora-gao-pic.oss-cn-beijing.aliyuncs.com/image-20211212160604076.png)

### 1.2.5 broker和集群

一个独立的 Kafka 服务器被称为 broker。 **broker 接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存**。 **broker 为消费者提供服务，对读取分区的请求作出响应，返回已经提交到磁盘上的消息**。根据特定的硬件及其性能特征，**单个 broker 可以轻松处理数千个分区以及每秒百万级的消息量**。

broker 是集群的组成部分。每个集群都有一个 broker 同时充当了**集群控制器**的角色（自动从集群的活跃成员中选举出来）。**控制器负责管理工作，包括将分区分配给 broker 和监控broker**。在集群中，一个分区从属于一个 broker，该broker 被称为分区的首领。一个分区可以分配给多个 broker ，这个时候会发生分区复制（见下图）。这种复制机制为分区提供了消息冗余，如果有一个 broker 失效，其他 broker 可以接管领导权。不过，相关的消费者和生产者都要重新连接到新的首领。

![image-20211212162049618](https://typora-gao-pic.oss-cn-beijing.aliyuncs.com/image-20211212162049618.png)

**保留消息**（在一定期限内）是 Kafka 一个重要特性。Kafka broker 默认的消息保留策略是这样的：要么保留一段时间（比如7天），要么保留到消息达到一定大小的字节数（比1GB ）。当消息数量达到这些上限时，旧消息就会过期井被 删除，所以在任何时刻，可用消息的总量都不会超过配置参数所指定的大小。**主题可以配置自己的保留策略**，可以将消息保留到不再使用它们为止。例如，用于跟踪用户活动的数据可能需要保留几天，而应用程序的度量指标可能只需要保留几个小时。可以通过配置把主题当作紧凑型日志。

### 1.2.6 多集群

使用多集群的原因：

- 数据类型分离
- 安全需求隔离
- 多数据中心

如果使用多个数据中心，就需要在它们之间复制消息。这样，在线应用程序才可以访问到多个站点的用户活动信息。例如，如果一个用户修改了他们的资料信息，不管从哪个数据中心都应该能看到这些改动。或者多个站点的监控数据可以被聚集到一个部署了分析程序和告警系统的中心位置。不过， Kafka 的消息复制机制只能在单个集群里进行，不能在多个集群之间进行。

## 1.3 为什么选择kafka

### 1.3.1 多个生产者

Kafka 可以无缝地支持多个生产者，不管客户端在使用单个主题还是多个主题。所以它很适合用来从多个前端系统收集数据，并以统一的格式对外提供数据。

### 1.3.2 多个消费者

除了支持多个生产者外，Kafka 也支持多个消费者从一个单独的消息流上读取数据，而消费者之间互不影响。这与其他队列系统不同，其他队列系统的消息一旦被一个客户端读取，其他客户端就无法再读取它。另外，多个消费者可以组成一个群组，它们共享一个消息流。

### 1.3.3 基于磁盘的数据存储

Kafka 不仅支持多个消费者，还允许消费者非实时地读取消息，这要归功于 Kafka 的数据保留特性。消息被提交到磁盘，根据设置的保留规则进行保存。**每个主题可以设置单独的保留规则**，以便满足不同消费者的需求，各个主题可以保留不同数量的消息。消费者可能会因为处理速度慢或突发的流量高峰导致无法及时读取消息，而持久化数据可以保证数据不会丢失。消费者可以在进行应用程序维护时离线一小段时间，而无需担心消息丢失或堵塞在生产者端。消费者可以被关闭，但消息会继续保留在 Kafka 里。消费者可以从上次中断的地方继续处理消息。

### 1.3.4 伸缩性

为了能够轻松处理大量数据， Kafka 从一开始就被设计成一个具有灵活伸缩性的系统。用户在开发阶段可以先使用单个 broker，再扩展到包含3个 broker 的小型开发集群，然后随着数据量不断增长，部署到生产环境的集群可能包含上百个 broker 。对在线集群进行扩展丝毫不影响整体系统的可用性。也就是说，一个包含多个 broker 的集群，即使个别 broker失效，仍然可以持续地为客户提供服务。要提高集群的容错能力，需要配置较高的复制系数。

### 1.3.5 高性能

上面提到的所有特性，让 Kafka 成为了 个高性能的发布与订阅消息系统。通过横向扩展生产者、消费者和 broker，Kafka 可以轻松处理巨大的消息流。**在处理大量数据的同时，它还能保证亚秒级的消息延迟**。

## 1.4 数据生态系统

### 1.活动跟踪

### 2.传递消息

### 3.度量指标和日志记录

### 4.提交日志

### 5.流处理


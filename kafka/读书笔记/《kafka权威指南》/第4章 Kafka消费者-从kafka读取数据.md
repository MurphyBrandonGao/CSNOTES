# 第4章 Kafka消费者-从kafka读取数据

## 4.1 KafkaConsumer概念

### 4.1.1 消费者和消费者群组

Kafka消费者从属于消费者群组，一个群组里的消费者订阅的是同一个主题，每个消费者接收主题一部分分区的消息。

往群组里增加消费者是**横向伸缩消费能力**的主要方式。消费者经常会做一些高延迟的操作，比如将数据写入到数据库或HDFS，或者进行比较耗时的计算，单个消费者无法跟上数据生成的速度，所以需要增加更多消费者。但是要注意不要让消费者的数量超过主题分区的数量，**多余的消费者只会被闲置**。

除了通过增加消费者来横向伸缩单个应用程序外，还经常出现多个应用程序从同一个主题读取数据的情况。每个应用程序都可以获取到主题的所有消息。横向伸缩消费者和消费者群组并不会对性能造成负面影响。

新增的消费者群组G2会从主题T1接收到所有消息，与群组G1之间互不影响：

![](https://typora-gao-pic.oss-cn-beijing.aliyuncs.com/iShot2021-11-07%2020.34.58.png)

总而言之，为每一个需要获取一个或多个主题全部消息的应用程序创建一个消费者群组，然后往群组里添加消费者来伸缩读取能力和处理能力，群组里的每个消费者只处理一部分消息。

### 4.1.2 消费者群组和分区再均衡

分区的所有权从一个消费者转移到另一个消费者，这样的行为称为**再均衡**，它为消费者群组带来了高可用性和伸缩性（我们可以放心的添加或移除消费者）。但是在再均衡期间，消费者无法读取消息，造成整个群组一小段时间的不可用。另外，当分区被重新分配给另一个消费者时，消费者当前的读取状态会丢失，还有可能需要去刷新缓存，在它恢复状态之前会拖慢应用程序。

消费者通过向被指派为**群组协调器**的broker（不同的群组可以有不同的协调器）发送心跳来维持它们和群组的从属关系以及它们对分区的所有权关系。只要消费者以正常的时间间隔发送心跳，就被认为是活跃的，说明它还在读取分区里的消息。消费者会在轮询消息（为了获取消息）或提交偏移量时发送心跳。如果消费者停止发送心跳的时间足够长，会话就会过期，群组协调器认为它已经死亡，就会触发一次再均衡。

如果 个消费者发生崩愤，井停止读取消息，群组协调器会等待几秒钟，确认它死亡了才触发再均衡。在这几秒钟时间里，死掉的消费者不会读取分区里的消息。在清理消费者时，消费者会通知协调器它将要离开群组，协调器会立即触发一次再均衡，尽量降低处理停顿。

**分配分区是怎样的一个过程**

当消费者要加入群组时，它会向群组协调器发送 Join Group 请求。第一个加入群组的消费者将成为“群主”。群主从协调器那里获得群组的成员列表（列表中包含了所有最近发送过心跳的消费者，它们被认为是活跃的），并负责给每一个悄费者分配分区。它使用一个实现了patitionAssignor接口的类来决定哪些分区应该被分配给哪个消费者。分配完毕之后，群主把分配情况列表发送给群组协调器，协调器再把这些信息发送给所有消费者。每个消费者只能看到自己的分配信息，只有群主知道群组里所有消费者的分配信息。这个过程会在每次再均衡时重复发生。

## 4.2 创建Kafka消费者

![](https://typora-gao-pic.oss-cn-beijing.aliyuncs.com/iShot2021-11-07%2022.28.38.png)

group.id属性指定了消费者所属群组的名字。创建不属于任何一个群组的消费者也是可以的，只是不常见。

## 4.3 订阅主题

创建好消费者之后就可以订阅主题了:

```java
consumer.subscibe(Collections.singletonlist("customerCountries"));
```

可以传入一个正则表达式，正则表达式可以匹配多个主题，如果创建了新主题并且名字与正则表达式匹配，那么会立即触发一次再均衡，消费者就可以读取新添加的主题。如果应用程序需要读取多个主题，并且可以处理不同类型的数据，那么这种订阅方式很管用，例如：

```java
consumer.subscribe("test.*");
```

## 4.4 轮询

一旦消费者订阅了主题，轮询就会处理所有细节，包括群组协调，分区再均衡，发送心跳和获取数据。

![image-20211123102923405](C:\Users\gaobo\AppData\Roaming\Typora\typora-user-images\image-20211123102923405.png)

1. 这是一个无限循环，消费者是一个长期运行的应用程序，通过持续轮询向kafka请求数据。
2. 消费者必须持续对kafka进行轮询，否则会被认为已经死亡，它的分区会被移交给群组里的其他消费者。传给poll()方法的参数是一个超时时间，用于控制poll()方法的阻塞时间，指定了方法在多久之后可以返回。
3. poll()方法返回的一个记录列表，每条列表都包含了记录所属主题的信息、分区信息、偏移量，以及记录的键值对。
4. 处理记录，一般会被保存到数据存储系统里。
5. 在退出应用程序之前使用close()方法关闭消费者，网络连接和socket也会随之关闭，并立即触发一次再均衡，而不是等待群组协调器发现它不再发送心跳井认定它已死亡，因为那样需要更长的时间，导致整个群组在一段时间内无法读取消息。

在第一次调用新消费者的poll()方法时，它会负责查找GroupCoordinator ， 然后加入群组，接受分配的分区。如果发生了再均衡，整个过程也是在轮询期间进行的。心跳也是从轮询里发送出去的。

## 4.5 消费者配置

1. fetch.min.bytes
2. fetch.max.wait.ms
3. max.partition.fetch.bytes
4. session.timeout.ms
5. auto.offset.reset
6. enable.auto.commit
7. partition.assignment.strategy
8. client.id
9. max.poll.records
10. receive.buffer.bytes和send.buffer.bytes

## 4.6 提交和偏移量

更新分区当前位置的操作叫**提交**。

消费者往一个叫作＿consul'ler_offset 的特殊主题发送消息，消息里包含每个分区的偏移量。如果消费者一直处于运行状态，那么偏移量就没有什么用处。不过，如果悄费者发生崩溃或者有新的消费者加入群组，就会触发再均衡，完成再均衡之后，每个消费者可能分配到新的分区，而不是之前处理的那个。为了能够继续
之前的工作，消费者需要读取每个分区最后一次提交的偏移量，然后从偏移量指定的地方继续处理。

如果提交的偏移量小于客户端处理的最后一个消息的偏移量，那么处于两个偏移量之间的消息就会被重复处理。

如果提交的偏移量大于客户端处理的最后一个消息的偏移量，那么处于两个偏移量之间的消息将会丢失。

### 4.6.1 自动提交

最简单的提交方式是让消费者自动提交偏移量。

如果enable.auto.commit 被设为true ，那么每过5s，消费者会自动把从poll()方法接收到的最大偏移量提交上去。提交时间间隔由auto.commit.interval.ms控制，默认值是5s。

假设我们仍然使用默认的5s 提交时间间隔，在最近一次提交之后的3s 发生了再均衡，再均衡之后，消费者从最后一次提交的偏移量位置开始读取消息。这个时候偏移量已经落后了3s ，所以在这3s 内到达的消息会被重复处理。

### 4.6.2 提交当前偏移量

大部分开发者通过控制偏移量提交时间来消除丢失消息的可能性，井在发生再均衡时减少重复消息的数量。消费者API提供了另一种提交偏移量的方式，开发者可以在必要的时候提交当前偏移盘，而不是基于时间间隔。

commitSync()提交由poll()方法返回的最新偏移量，提交成功后马上返回，如果提交失败就抛出异常。

![image-20211123193827271](D:\CSNOTES\kafka\读书笔记\《kafka权威指南》\image-20211123193827271.png)

1. 处理消息
2. 处理完当前批次消息，在轮询更多消息之前，调用commitSync()方法提交当前批次最新的偏移量
3. 只要没有发生不可恢复的错误，commitSync()方法会**一直尝试直至提交成功**，如果提交失败，打印错误日志

### 4.6.3 异步提交

手动提交有一个不足之处，在broker 对提交请求作出回应之前，应用程序会一直阻塞，这样会限制应用程序的吞吐量。我们可以通过降低提交频率来提升吞吐量，但如果发生了再均衡， 会增加重复消息的数量。

![image-20211123194847454](D:\CSNOTES\kafka\读书笔记\《kafka权威指南》\image-20211123194847454.png)

1. 提交最后一个偏移量，然后继续做其他事情。

在成功提交或碰到无法恢复的错误之前，commitSync() 会一直重试，但是commitAsync()不会，这也是commitAync不好的一个地方。它之所以不进行重试，是因为在它收到服务器响应的时候，可能有一个更大的偏移量已经提交成功。假设我们发出一个请求用于提交偏移量2000 ，这个时候发生了短暂的通信问题，服务器收不到请求，自然也不会作出任何响应。与此同时，我们处理了另外一批消息，并成功提交了偏移量3000 。如果commitAsync () 重新尝试提交偏移量2000 ，它有可能在偏移量3000 之后提交成功。这个时候如果发生再均衡，就会出现重复消息。

我们之所以提到这个问题的复杂性和提交顺序的重要性，是因为commitAsync()也支持回调，在broker 作出响应时会执行回调。回调经常被用于记录提交错误或生成度量指标， 不过如果你要用它来进行重试， 一定要注意提交的顺序。

![image-20211123204334449](D:\CSNOTES\kafka\读书笔记\《kafka权威指南》\image-20211123204334449.png)

1. 发送提交请求然后继续做其他事情，如果提交失败，错误信息和偏移量会被记录下来。



重试异步提交

我们可以使用一个单调递增的序列号来维护异步提交的顺序。在每次提交偏移量之后或在回调里提交偏移量时递增序列号。在进行重试前，先检查回调的序列号和即将提交的偏移量是否相等，如果相等，说明没有新的提交，那么可以安全地进行重试。如果序列号比较大，说明有一个新的提交已经发送出去了，应该停止重试。

### 4.6.4 同步和异步组合提交

一般情况下，针对偶尔出现的提交失败，不进行重试不会有太大问题，因为如果提交失败是因为临时问题导致的，那么后续的提交总会有成功的。但如果这是发生在关闭消费者或再均衡前的最后一次提交，就要确保能够提交成功。

![image-20211123205407005](D:\CSNOTES\kafka\读书笔记\《kafka权威指南》\image-20211123205407005.png)

1. 如果一切正常，我们使用commitAsync()方法来提交。这样速度更快，而且即使这次提交失败，下一次提交很可能会成功。
2. 如果直接关闭消费者，就没有所谓的”下一次提交“了。使用commitSync()方法会一直重试，直到提交成功或发生无法恢复的错误。

### 4.6.5 提交特定的偏移量

![image-20211123224029479](D:\CSNOTES\kafka\读书笔记\《kafka权威指南》\image-20211123224029479.png)

1. 用于跟踪偏移量的map
2. 处理消息
3. 读取每条记录之后，使用期望处理的下一个消息的偏移量更新map里的偏移量，下一次就从这里开始读取消息。
4. 每处理1000次记录就提交一次偏移量。
5. 调用的是commitAsync()，不过调用commitAsync()也是完全可以的。

## 4.7 再均衡监听器

> fdsdsf


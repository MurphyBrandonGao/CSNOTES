# 第6章 可靠的数据传递

## 6.1 可靠性保证

在讨论可靠性时，我们一般会使用**保证**这个词，它是指确保系统在各种不同的环境下能够发生一致的行为。例如ACID是关系型数据库普遍支持的标准可靠性保证。

kafka在以下方面做出了可靠性保证：

- kafka可以保证分区消息的顺序。如果使用同一个生产者往同一个分区写入消息，而且消息B在消息A之后写入，那么 Kafka 可以保证消息B的偏移量比消息A的偏移量大，而且消费者会先读取消息A再读取消息B。
- 只有当消息被写入分区的所有同步副本时（但不一定要写入磁盘），它才被认为是“已提交”的。
- 只要还有一个副本是活跃的，那么已经提交的消息就不会丢失。
- 消费者只能读取已经提交的消息。

## 6.2 复制

kafka的复制机制和分区的多副本架构是kafka可靠性保证的核心。把消息写入多个副本可以使kafka在发生崩溃时仍能保证消息的持久性。

Kafka 的主题被分为多个分区，分区是基本的数据块。分区存储在单个磁盘上，Kafka 可以保证分区里的事件是有序的，分区可以在线（可用），也可以离线（不可用）。每个分区可以有多个副本，其中一个副本是首领。所有的事件都直接发送给首领副本，或者直接从首领副本读取事件。其他副本只需要与首领保持同步，并及时复制最新的事件。当首领副本不可用时，其中一个同步副本将成为新首领。

分区副本一定是同步副本，而对于跟随者副本来说，它需要满足以下条件才能认为是同步的：

- 与 Zookeeper 之间有一个活跃的会话，也就是说，它在过去的6s（可配置）内向 Zookeeper 发送过心跳。
- 在过去的10s内（可配置）从首领那里获取过消息。
- 在过去的10s内从首领那里获取过最新的消息。光从首领那里获取消息是不够的，它还必须是**几乎零延迟**的。

一个不同步的副本通过与 Zookeeper 重新建立连接，井从首领那里获取最新消息，可以重新变成同步的。这个过程在网络出现临时问题井很快得到修复的情况下会很快完成，但如果 broker 发生崩溃时就需要较长的时间。

**非同步副本**

如果一个或多个副本在同步和非同步状态之间快速切换，说明集群内部出现了问题，通常是Java不恰当的垃圾回收配置导致的。不恰当的垃圾回收配置会造成几秒钟的停顿，从而让broker与zookeeper之间断开连接，最后变成不同步的，进而发生状态切换。

一个滞后的同步副本会导致生产者和消费者变慢，因为在消息被认为已提交之前，客户端会等待所有同步副本接收消息。而如果一个副本不再同步了，我们就不再关心它是否已经收到消息。虽然非同步副本同样滞后，但它并不会对性能产生任何影响。但是，更少的同步副本意味着更低的有效复制系数，在发生岩机时丢失数据的风险更大。

## 6.3 broker配置

broker 有3个配置参数会影响 Kafka 消息存储的可靠性。与其他配置参数一样，它们可以用在 **broker 级别**，用于控制**所有主题的行为**，也可以应用在**主题级别**，用于控制**个别主题的行为**。

### 6.3.1 复制系数

主题级别的配置参数是 replication.factor，而在 broker 级别则可以通过 default.replication.factor 来配置自动创建的主题。

如果复制系数为N，那么在N-1个broker失效的情况下，仍能从主题读取数据或向主题写入数据。所以，**更高的复制系数会带来更高的可用性、可靠性和更少的故障**。另一方面，复制系数N需要至少N个broker，而且会有N个数据副本，会占用N倍的磁盘空间，因此**要在可用性和存储硬件之间作出权衡**。

如果因 broker 重启导致的主题不可用是可接受的（这在集群里是很正常的行为），那么把复制系数设为 1 就可以了。在作出这个权衡的时候，要确保这样不会对你的组织和用户造成影响，因为你在节省了硬件成本的同时也降低了可用性。复制系数为 2 意味着可以容忍1个broker 发生失效，看起来已经足够了。不过要记住，有时候 broker 发生失效会导致集群不稳定（通常是旧版的 Kafka ），迫使你重启另 一个 broker 一集群控制器。也就是说，如果将复制系数设为 2，就有可能因为重启等问题导致集群不可用。所以这是一个两难的选择。

基于以上几点原因，我们建议在要求可用性的场景里把复制系数设为 3。在大多数情况下，这已经足够安全了。

副本的分布也很重要。默认情况下，kafka会确保分区的每个副本被放在不同的broker上，并且建议broker分布在多个不同的机架上。

### 6.3.2 不完全的首领选举

当分区首领不可用时，一个同步副本会被选为新首领。如果在选举过程中没有丢失数据，也就是说提交的数据同时存在于所有的同步副本上，那么这个选举就是“完全”的。

但如果在首领不可用时其他副本都是不同步的，我们该怎么办呢？

这种情况会在以下两种场景里出现。

- 分区有3个副本，其中的两个跟随者副本不可用（比如有两个 broker 发生崩溃）。这个时候，如果生产者继续往首领写入数据，所有消息都会得到确认井被提交（因为此时领是唯一的同步副本）。现在我们假设首领也不可用 了（又一个 broker 发生崩溃），这个时候，如果之前的一个跟随者重新启动，它就成为了分区的唯一不同步副本。

- 分区有3个副本，因为网络问题导致两个跟随者副本复制消息滞后，所以尽管它们还在复制消息，但已经不同步了。首领作为唯一的同步副本继续接收消息。这个时候，如果首领变为不可用，另外两个副本就再也无法变成同步的了。

对于这两种场景，我们要作出两难的选择。

- 如果不同步的副本不能被选举为新首领，那么分区在旧首领（最后一个同步副本）恢复之前是不可用的。有时候这种状态会持续数小时。（降低了可用性）
- 如果不同步的副本可以被选举为新首领，那么在这个副本变为不同步之后写入旧首领的消息会全部丢失，导致**数据不一致**。为什么会这样呢？假设在副本0和副本1不可用时，偏移量 100-200 的消息被写入副本 2（首领）。现在副本2变为不可用的，而副本0变为可用的。副本0只包含偏移量 O～ 100 的消息，不包含偏移量 100~200 的消息。如果我们允许副本0成为新首领，生产者就可以继续写人数据，消费者可以继续读取数据。于是新首领就有了偏移量 100 200 的新消息。这样，部分消费者会读取到偏移量100~200的旧消息，部分消费者会读取到偏移量100~200 的新消息，还有部分消费者读取的是二者的混合。这样会导致非常不好的结果，比如生成不准确的报表。另外 ，副本2可能会重新变为可用，并成为新首领的跟随者。这个时候，它会把比当前首领旧的消息全部删除，而这些消息对于所有消费者来说都是不可用的。（数据不一致、消息丢失）

简而言之，如果我们允许不同步的副本成为首领，那么就要承担**丢失数据和出现数据不一致**的风险。 如果不允许它们成为首领，那么就要接受**较低的可用性**，因为我们必须等待原先的首领恢复到可用状态。

如果把 unclean.leader.election.enable 设为 true ，就是**允许不同步的副本成为首领**（也就是“**不完全的选举**"），那么我们将面临丢失消息的风险。如果把这个参数设为 false 就要等待原先的首领重新上线，从而降低了可用性。

### 6.3.3 最少同步副本

在主题级别和broker级别上，这个参数都叫 min.insync.replicas。

如果要确保已提交的数据被写入不止一个副本，就需要把最少同步副本数量设置为大一点的值。例如对于一个包含3个副本的主题，如果min.insync.replicas被设置为2，那么至少要存在2个同步副本才能向分区写入数据。

如果3个副本都是同步的，或者其中1个副本变为不可用，都不会有什么问题。不过，如果有2个副本变为不可用，那么 **broker 就会停止接受生产者的请求**。尝试发送数据的生产者会收到 notEnoughReplicasException 异常。**消费者仍然可以继续读取已有的数据**。实际上，如果使用这样的配置，那么当只剩下1个同步副本时，它就变成**只读**了，这是为了避免在发生不完全选举时数据的写入和读取出现非预期的行为。为了从只读状态中恢复，必须让2个不可用的分区中的一个重新变为可用的（比如重启broker)，并等待它变为同步的。

## 6.4 在可靠的系统里使用生产者

即使我们尽可能把 broker 配置得很可靠，但如果没有对生产者进行可靠性方面的配置，整个系统仍然有可能出现突发性的数据丢失。

- 为 broker 配置了3个副本，井且禁用了不完全首领选举，这样应该可以保证万无一失。我们把生产者发送消息的 acks 设为1（只要首领接收到消息就可以认为消息写入成功）。生产者发送一个消息给首领，首领成功写入，但跟随者副本还没有接收到这个消息。首领向生产者发送了一个响应，告诉它“消息写入成功”，然后它崩溃了，而此时消息还没有被其他副本复制过去。**另外两个副本此时仍然被认为是同步的（毕竟判定一个副本不同步需要一小段时间**），而且其中的一个副本成了新的首领。因为消息还没有被写入这个副本，所以就丢失了，但发送消息的客户端却认为消息已成功。因为消费者看不到丢失的消息，所以此时的系统仍然是一致的（因为副本没有收到这个消息，所以消息不算已提交），但从生产者角度来看，它丢失了一个消息。
- 为 broker 配置了3个副本，并且禁用了不完全首领选举。我们接受了之前的教训，把生产者的 acks 设为 all 。假设现在往 Kafka 发送消息，分区的首领刚好崩溃，新的首领正在选举当中， Kafka 会向生产者返回“首领不可用”的响应。在这个时候，**如果生成者没能正确处理这个错误，也没有重试发送消息直到发送成功，那么消息也有可能丢失。**这算不上是 broker 的可靠性问题，因为 broker 并没有收到这个消息。这也不是一致性问题，因为消费者井没有读到这个消息。问题在于如果生产者没能正确处理这些错误，弄丢消息的是它们自己。

该如何避免这些问题呢？

- 根据可靠性需求配置恰当的acks值
- 在参数配置和代码里正确处理错误

### 6.4.1 发生确认

生产者可以选择以下3种不同的确认模式：

- **acks=0 意味着如果生产者能够通过网络把消息发送出去，那么就认为消息已成功写入Kafka**。在这种情况下还是有可能发生错误，比如发送的**对象无法被序列化或者网卡发生故障**，但如果是分区离线或整个集群长时间不可用，那就不会收到任何错误。即使在发生完全首领选举的情况下，这种模式仍然会丢失消息，因为在新首领选举过程中并不知道首领已经不可用了。在 acks=0 模式下的运行速度是非常快的，可以得到**惊人的吞吐 和带宽利用**，不过如果选择了这种模式， **一定会丢失一些消息**。
- **acks=1 意味着首领在收到消息并把它写入到分区数据文件（不一定同步到磁盘上）时会返回确认或错误响应**。在这个模式下，如果发生正常的首领选举，生产者会在选举时收到 LeaderNotAvailableException 异常，如果生产者能恰当地处理这个错误，它会重试发送消息，最终消息会安全到达新的首领那里。不过在这个模式下仍然有可能丢失数据，比如消息已经成功写入首领，但在消息被复制到跟随者副本之前首领发生崩溃。
- **acks=all 意味着首领在返回确认或错误响应之前，会等待所有同步副本都收到消息**。如果和 min.insync.replicas 参数结合起来，就可以决定在返回确认前至少有多少个副本能够收到消息。这是**最保险**的做法一一生产者会一直重试直到消息被成功提交。不过这也是**最慢**的做法，生产者在继续发送其他消息之前需要等待所有副本都收到当前的消息。可以通过使用异步模式和更大的批次来加快速度，但这样做通常会降低吞吐量。

### 6.4.2 配置生产者的重试参数

生产者需要处理的错误包括两部分：一部分是**生产者可以自动处理的错误（可重试错误）**，还有一部分是**要开发者手动处理的错误（不可重试错误）**。

**如果 broker 返回的错误可以通过重试来解决，那么生产者会自动处理这些错误**。生产者向 broker 发送消息时，broker 可以返回一个成功响应码或者一个错误响应码。错误响应码可以分为两种，一种是在重试之后可以解决的，还有一种是无法通过重试解决的。例如，如果broker 返回的是 LEADER_NOT_AVAILABLE 错误，生产者可以尝试重新发送消息。也许在这个时候一个新的首领被选举出来了，那么这次发送就会成功。 也就是说， LEADER_NOT_AVAILABLE是一个**可重试错误**。另一方面，如果 broker 返回的是 INVALID_CONFIG 错误，即使通过重试也无法改变配置选项，所以这样的重试是没有意义的。这种错误是**不可重试错误**。

一般情况下，如果你的目标是不丢失任何消息，那么最好让生产者在遇到可重试错误时能够保持重试。为什么要这样？因为像**首领选举**或**网络连接**这类问题都可以在几秒钟之内得到解决，如果让生产者保持重试，你就不需要额外去处理这些问题了。

**要注意，重试发送一个已经失败的消息会带来一些风险，如果两个消息都写入成功，会导致消息重复**。例如，生产者因为网络问题没有收到 broker 的确认，但实际上消息已经写入成功，生产者会认为网络出现了临时故障，就重试发送该消息（因为它不知道消息已经写入成功）。在这种情况下，broker 会收到两个相同的消息。重试和恰当的错误处理可以保证每个消息“至少被保存一次”，但当前的 Kafka 版本（0.10.0 ）无法保证每个消息“只被保存一次”。现实中的很多应用程序**在消息里加入唯一标识符，用于检测重复消息，消费者在读取消息时可以对它们进行清理**。还要一些应用程序可以做到**消息的“幂等”**，也就说，即使出现了重复消息，也不会对处理结果的正确性造成负面影响。

### 6.4.3 额外的错误处理

使用生产者内置的重试机制可以轻松处理大部分可重试错误。对于开发人员来说，也要处理其他类型的错误，包括：

- 不可重试的broker错误，例如消息的大小错误、认证错误等；
- 在消息发送之前发生的错误，例如序列化错误；
- 在生产者达到重试次数上限时或者在消息占用的内存达到上限时发生的错误。

在第3章讨论了如何为同步发送消息和异步发送消息编写错误处理器。这些错误处理器的代码逻辑与具体的应用程序及其目标有关。丢弃“不合法的消息”？把错误记录下来？把这些消息保存在本地磁盘上？回调另一个应用程序？具体使用哪一种逻辑要根据具体的架构来决定。只要记住，如果错误处理只是为了重试发送消息，那么最好还是使用生产者内置的重试机制。

## 6.5 在可靠的系统里使用消费者

在从分区读取数据时，消费者会获取一批事件，检查这批事件里最大的偏移量，然后从这个偏移量开始读取另外一批事件。这样可以保证消费者总能以正确的顺序获取新数据，不会错过任何事件。

如果一个消费者退出，另一个消费者需要知道从什么地方开始继续处理，它需要知道前一个消费者在退出前处理的最后一个偏移量是多少。所谓的“另一个”消费者，也可能就是它自己重启之后重新回来工作。这也就是为什么消费者要“提交”它们的偏移量。它们把当前读取的偏移量保存起来，在退出之后，同一个群组里的其他消费者就可以接受它们的工作。如果**消费者提交了偏移量却未能处理完消息，那么就有可能造成消息丢失，这也是消费者丢失消息的主要原因**。在这种情况下，如果其他消费者接手了工作，那些没有被处理完的消息就会被忽略，永远得不到处理。这就是为什么我们非常重视偏移量提交的时间点和提交的方式。

**已提交消息与已提交偏移量**

**已提交消息**是指已经被写入所有同步副本并且对消费者可见的消息，而**已提交偏移量**是指消费者发送给 Kafka 的偏移量，用于确认它已经收到并处理好的消息位置。

### 6.5.1 消费者的可靠性配置

- group.id：如果两个消费者具有相同的group.id井且订阅了同一个主题，那么每个消费者会分到主题分区的一个子集，也就是说它们只能读到所有消息的一个子集（不过群组会读取主题所有的消息）。如果你希望消费者可以看到主题的所有消息，那么需要为它设置唯一的group.id
- Auto.offset.reset：这个参数指定了在没有偏移量可提交时（比如消费者第一次启动时）或者请求的偏移量在 broker 上不存在时，消费者会做些什么。这个参数有两种配置。一种是 earliest，如果选择了这种配置，消费者会从分区的开始位置读取数据，不管偏移量是否有效，这样会导致消费者读取大量的重复数据，但可以保证最少的数据丢失。 另一种是 latest ，如果选择了这种配置，消费者会从分区的末尾开始读取数据，这样可以减少重复处理消息，但很有可能会错过一些消息。
- enable.auto.commit：你可以让消费者基于任务调度自动提交偏移量 ，也可以在代码里手动提交偏移量。**自动提交的一个最大好处是，在实现消费者逻辑时可以少考虑一些问题**。如果你在消费者轮询操作里处理所有的数据，那么**自动提交可以保证只提交已经处理过的偏移量**。自动提交的主要缺点是，**无法控制重复处理消息（比如消费者在自动提交偏移量之前停止处理消息），而且如果把消息交给另外一个后台线程去处理，自动提交机制可能会在消息还没有处理完毕就提交偏移量**。
- auto.commit.interval.ms：如果选择了自动提交偏移量，可以通过该参数配置提交的频度，默认值是每5秒钟提交一次。一般来说，频繁提交会增加额外开销，但也会降低重复处理消息的概率。

### 6.5.2 显式提交偏移量

